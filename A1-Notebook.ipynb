{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06797264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the notebook\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d85109c",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf858f47",
   "metadata": {},
   "source": [
    "## NLP Model \n",
    "\n",
    "Load a hate speech classification model via HuggingFace pipeline. Please read through [this tutorial](https://huggingface.co/docs/transformers/pipeline_tutorial) to learn more about the pipeline -- you only need to read until \"Audio Pipeline\". In a nutshell, you will:\n",
    "\n",
    "> pick an appropriate model, load it with the corresponding AutoModelFor and AutoTokenizer class.\n",
    "\n",
    "\n",
    "**Please do so by changing the next code block.**\n",
    "\n",
    "### Tips on picking tasks and models:\n",
    "\n",
    "1. [This tutorial](https://github.com/huggingface/notebooks/blob/main/transformers_doc/en/quicktour.ipynb) has a more comprehensive introduction on HuggingFace.\n",
    "2. If you are unsure about the tasks / datasets, [HuggingFace models](https://huggingface.co/models) have useful tags on the left that can be used as filters.\n",
    "3. Please pick a task that has a supported pipeline structure. [This page has all the pipelines and examples](https://huggingface.co/docs/transformers/main_classes/pipelines#natural-language-processing).\n",
    "4. Please pick models that are:\n",
    "    - Well-documented (e.g., describes how it's finetuned, notes its perfromances, has usage instructions, has an inference API). These models are usually less buggy. For example, [Distilbert-SST-2](https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english) is quite well-documented.\n",
    "    - Small if you do not have GPU (smaller models are usually less accurate but will give you predictions more quickly.) You can check the `pytorch_model.bin` size (e.g., [here](https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english/tree/main))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3665df0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# select a model through Transformers Pipeline.\n",
    "task_name = hate speech classification\n",
    "model_name = \"MODEL_NAME\"\n",
    "# If you have GPU, you can change this to 0 or other devices\n",
    "device=-1\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "pipe = pipeline(\n",
    "    task=task_name, \n",
    "    model=model_name, \n",
    "    device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f37540",
   "metadata": {},
   "source": [
    "## Load Dataset\n",
    "\n",
    "Find a dataset to use as your base dataset for further data slicing and perturbations, via [HuggingFace Datasets](https://huggingface.co/docs/datasets/index). See [the tutorial here](https://huggingface.co/docs/datasets/tutorial)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634c54ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset_name = \"DATASET_NAME\"\n",
    "split = \"dev\"\n",
    "dataset = load_dataset(dataset_name, split=split)\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfca1a0",
   "metadata": {},
   "source": [
    "# Write Tests\n",
    "\n",
    "Assume you are an AI engineer building this model Your task is to come up with multiple tests to assess the model, and figure out when it works well and when it (potentially) contains bugs. You should proceed with the mindset that these tests you create to evaluate this model will also be used to test future models before they go into production!\n",
    "\n",
    "Your completed test suite will go through peer reviews, and your fellow students will rate the result of each test as to its severity, from 'not a bug' to 'very severe bug'. As mentioned in README, more severe bugs will give you higher grade :)\n",
    "\n",
    "From this point, you will:\n",
    "1. Learn to use CheckList. You should check out [its readme and tutorials here](https://github.com/marcotcr/checklist).\n",
    "2. Write tests for your selected model. Try to write:\n",
    "    - At least 10 tests\n",
    "    - Write tests that can expose more severe bugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b4a0b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import checklist\n",
    "from checklist.test_suite import TestSuite\n",
    "# create a test suite\n",
    "suite = TestSuite()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f65a44be",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use the following blocks -- and add more -- to create your tests after reading the checklist tutotrials. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ac7cd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397e403f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438d1163",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9376fdce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036d39e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6cc1a375",
   "metadata": {},
   "source": [
    "# Summarize and Save the Result\n",
    "\n",
    "If you are missing some tests, please go back, re-run them and add them. Once you are done, call the command below, to start rating your tests:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c7aa10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see the results\n",
    "suite.visual_summary_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f261ff8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the result\n",
    "suite.save(\"./A1-Suite.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658a497a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure the results correctly saved!\n",
    "import checklist\n",
    "from checklist.test_suite import TestSuite\n",
    "# create a test suite\n",
    "suite2 = TestSuite.from_file(\"./A1-Suite.pkl\")\n",
    "suite2.visual_summary_table()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
